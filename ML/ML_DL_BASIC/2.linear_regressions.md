강의: http://www.edwith.org/others26/lecture/10731/

# Linear Regression
하나의 가설을 세워야 Regression 모델 학습이 가능하다.
가설(H, Hyphothesis)의 형태가 일차 방정식으로 표현 가능할때 Linear Regression이라 칭한다.
> H(x) = Wx + b

## Cost(Loss function)
우리가 세운 가설과 실제 데이터가 얼마나 다른지 계산하는 함수
cost(W,b)가 적을 수록 좋으며, minimize cost를 하기 위해 linear regression을 학습시킨다.

![Cost function](../images/cost_function.png)


## Gradient Descent Algorithm
- cost minimization을 위한 알고리즘.
- cost 함수 그래프를 그리면 2차 포물선이 그려짐.
- cost의 최솟값은 미분을 통해 해결할 수 있다.
![Gradient_descent](../images/gradient_descent.png)
